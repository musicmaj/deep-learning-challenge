Neural Network Report
Kade Rivers


Overview
The purpose of this Neural Network assignment was to read in a csv containing information on successful funding projects from a company called Alphabet Soup. The goal of the network was to create a binary classifier that can predict whether applicants will be successful if funded by Alphabet Soup. The csv was placed into a dataframe, cleaned, and organized to create a neural network. A variety of models and methods were used within the models to be able to present the top prediction out of all 4 required models and among the many others tried in the process.
Data Preprocessing
        Prior to creating a neural network, the csv file was read into a data frame in jupyter notebook via Google Colab. EIN and name columns were dropped as instructed, and the Application Type and Classification thresholds were set to various values depending on the model to test out different accuracies depending on those thresholds. One module included removing additional columns to determine if the accuracy would improve. After initial data adjustments, a scaler was used on the “ASK_AMT” column and various amounts of layers were added depending on the model in use. The target for this project is whether or not the projects were successful, and the features are the remaining columns after column removal.
Compiling, Training, and Evaluating the Model
        For this project there were four required models, however, I tested out many more over the course of a few hours to tinker with the layers, units, dropout, different activations, and even tested out all the available optimizers I could find for Keras.
        With all my tests, I discovered that “relu” and “sigmoid” were the top functioning activations–with sigmoid being in the output layer. I discovered that adjusting the Dropout could have a positive impact on the overall accuracy, and that adjusting the units significantly impacted the results every time they were adjusted.
        The top optimizers for this particular network were “adam”, “nadam”, “adamw” and “rmsprop” did alright as well, however, “adam” remained at the top of my list almost every single time with “nadam” only once in awhile having higher accuracies.
        Finally, I adjusted epoch and batch sizes to try and gain the highest amount of accuracy I was able to, and my top accuracy was around 73%. I even utilized various articles and suggestions on how to improve the accuracy, but could not achieve the 75% I had hoped for.
        Of all the models I tried, my top performing neural network had 3 layers and an output layer. The units were 7, 5, 3, and 1 and I trained with 75 epochs. This got me to 73% accuracy. My final model reached 72.9% and had 6 layers, a dropout layer, and an output layer. I utilized larger amounts of units between 128 and 256. I also tested out various batch sizes from 50-1000.
Summary and Recommendations
        While I did not achieve 75% accuracy, I did achieve trying out probably close to 100 different variations on the numbers, maybe even over 100, and I feel as if I have done my due diligence on this task at hand. If I were truly working for this company and needed to reach the 75% at a minimum, I would consider trying out additional options such as the machine learning I learned and utilized in my previous assignment. I would also contact some of my references to share my findings and ask for guidance to increase the accuracy for my company.